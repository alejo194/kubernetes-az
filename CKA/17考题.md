##### 1 RBAC
```bash
kubectl create clusterrole deployment-clusterrole --verb=create --resource=deployment,statefulsets,daemonsets

kubectl create sa cicd-token -n app-team1

kubectl create rolebinding cicd-token-binding --clusterrole=deployment-clusterrole --serviceaccount=app-team1:cicd-token --namespace=app-team1
```
##### 2 节点维护
+ 将ek8s-node-1节点设置为不可用，然后重新调度该节点上的所有Pod
```bash
kubectl config use-context ek8s
kubectl cordon ek8s-node-1 # 设置节点不可调度状态
kubectl drain ek8s-node-1 --delete-emptydir-data --ignore-daemonsets --force # 驱逐ek8s-node-1 所有的pod
```
##### 3 节点升级
+ 升级主节点及kubectl，kubelet.注意其他etcd,containerd,dns不需要升级
```bash
#设置为维护状态
$ kubectl config use-context mk8s
$ kubectl get no
$ kubectl cordon k8s-master
$ kubectl drain k8s-master --delete-emptydir-data --ignore-daemonsets --force

#安装题目提示ssh到一个master节点
$ ssh mk8s-master
$ apt update
$ apt-cache policy kubeadm |grep 1.19.0
$ apt-get install kubeadm=1.19.0-00

#验证升级计划
$ kubeadm upgrade plan
# 看到如下信息，可升级到指定版本
You can now apply the upgrade by executing the following command.
        kubeadm upgrade apply v1.19.0
        # 开始升级Master节点
        $ kubeadm upgrade apply v1.19.0 --etcd-upgrade=false
        [upgrade/sucdessful] SUCCESS Your cluster was upgraded to 'v1.19.0'.EnJoy
        
        [upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven't already done so.
        
        #升级kubectl和kubelet
        $ apt-get install -y kubelet=1.19.0-00 kubectl=1.19.0-00
        $ systemctl daemon-reload
        $ systemctl restart kubelet
        
        $ kubectl uncordon k8s-master
        node/k8s-master uncordoned
        
        $ kubectl get node
```
##### 4 etcd的备份和还原
```bash
#备份
ETCDCTL_API=3 etcdctl --endpoints="https://127.0.0.1:2379" --cacert=/opt/KUIN000601/ca.crt --cert=/opt/KUIN000601/etcd-client.crt --key=/opt/KUIN000601/etcd-client.key snapshot save /srv/data/etcd-snapshot.db
#还原
$ mkdir /opt/backup -p
$ cd /etc/kubernetes/manifests && mv kube-* /opt/backup
$ export ETCDCTL_API=3
$ etcdctl --endpoints="https://127.0.0.1" --cacert=/opt/KUIN000601/ca.crt --cert=/opt/KUIN000601/etcd-clinet.crt --key=/opt/KUIN000601/etc-client.key snapshot restore /var/lib/backup/etcd-snapshot-previous.db --data-dir=/var/lib/etcd-restore
  
  $ vim etcd.yaml
  # 将volume配置的path:/var/lib/etcd改为/var/lib/etcd-restore
    volumes：
    - hostPath:
        path: /etc/kubernetes/pki/etcd
        type: DirectoryOrCreate
       name: etcd-certs
    - hostPath:
        path: /var/lib/etcd-restore
    
  # 还原k8s组件
  $ mv /opt/backup/* /etc/kubernetes/manifests
  $ systemctl restart kubelet
```
##### 5 网络策略networkPolices
```bash
apiVersion: networking.k8s.io/v1
kind: NetworkPlicy
metadata:
  name: test-network-policy
  namespace: default
spec:
  podSelector:
    matchLabels:
      role: db
  policyTypes:
    - Ingress
    - Egress
  ingress:
    - from:
        - ipBlock:
            cidr: 172.17.0.0/16
            except:
              - 172.17.1.0/24
        - namespaceSelector:
            matchLabels:
              project: myproject
        - podSelector:
            matchLabels:
              role: frontend
      ports:
        - protocol: TCP
          port: 6379
   egress:
     - to:
         - ipBlock:
             cidr: 10.0.0.0/24
       ports:
         - protocol: TCP
           port:5978
```
